{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5Yy9ahrbz4D",
        "outputId": "6427d03a-a4d0-4150-a5b5-7d665919caeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-04 11:19:31--  https://www.dropbox.com/s/eduk281didil1km/Weekly_U.S.Diesel_Retail_Prices.csv?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/eduk281didil1km/Weekly_U.S.Diesel_Retail_Prices.csv [following]\n",
            "--2022-02-04 11:19:31--  https://www.dropbox.com/s/dl/eduk281didil1km/Weekly_U.S.Diesel_Retail_Prices.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca5c016f955d4fc50af8f7fa383.dl.dropboxusercontent.com/cd/0/get/BfHXJ9LOgaBJawer5oxLa2Pc5B4TVgXxqIbfFPUDwCD-DcemWD0YmFKJ2xWsucYttpIKryHGDBOjLIGCxYJLSZoCe1mSwfZZ-DrjrX9GFe7ydeGznvY9IJpLP2vM8YMxqyDvkf4jv4fv1AHJVU2bJdgR/file?dl=1# [following]\n",
            "--2022-02-04 11:19:31--  https://uca5c016f955d4fc50af8f7fa383.dl.dropboxusercontent.com/cd/0/get/BfHXJ9LOgaBJawer5oxLa2Pc5B4TVgXxqIbfFPUDwCD-DcemWD0YmFKJ2xWsucYttpIKryHGDBOjLIGCxYJLSZoCe1mSwfZZ-DrjrX9GFe7ydeGznvY9IJpLP2vM8YMxqyDvkf4jv4fv1AHJVU2bJdgR/file?dl=1\n",
            "Resolving uca5c016f955d4fc50af8f7fa383.dl.dropboxusercontent.com (uca5c016f955d4fc50af8f7fa383.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to uca5c016f955d4fc50af8f7fa383.dl.dropboxusercontent.com (uca5c016f955d4fc50af8f7fa383.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/binary]\n",
            "Saving to: ‘Weekly_U.S.Diesel_Retail_Prices.csv?dl=1’\n",
            "\n",
            "Weekly_U.S.Diesel_R     [ <=>                ]  28.28K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-02-04 11:19:32 (204 KB/s) - ‘Weekly_U.S.Diesel_Retail_Prices.csv?dl=1’ saved [28959]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/eduk281didil1km/Weekly_U.S.Diesel_Retail_Prices.csv?dl=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# This function normalizes the dataset using min max scaling.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "def normalize_series(data, min, max):\n",
        "    data = data - min\n",
        "    data = data / max\n",
        "    return data\n",
        "\n",
        "# DO NOT CHANGE THIS.\n",
        "def windowed_dataset(series, batch_size, n_past=10, n_future=10, shift=1):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(size=n_past + n_future, shift=shift, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n",
        "    ds = ds.map(lambda w: (w[:n_past], w[n_past:]))\n",
        "    return ds.batch(batch_size).prefetch(1)\n",
        "\n",
        "\n",
        "def solution_model():\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    # Reads the dataset.\n",
        "    df = pd.read_csv('Weekly_U.S.Diesel_Retail_Prices.csv?dl=1',\n",
        "                     infer_datetime_format=True, index_col='Week of', header=0)\n",
        "    \n",
        "    N_FEATURES = len(df.columns) # DO NOT CHANGE THIS\n",
        "    \n",
        "    # Normalizes the data\n",
        "    data = df.values\n",
        "    data = normalize_series(data, data.min(axis=0), data.max(axis=0))\n",
        "    \n",
        "    # Splits the data into training and validation sets.\n",
        "    SPLIT_TIME = int(len(data) * 0.8) # DO NOT CHANGE THIS\n",
        "    x_train = data[:SPLIT_TIME]\n",
        "    x_valid = data[SPLIT_TIME:]\n",
        "\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    tf.keras.backend.clear_session()\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    BATCH_SIZE = 32  # ADVISED NOT TO CHANGE THIS\n",
        "    N_PAST = 10  # DO NOT CHANGE THIS\n",
        "    N_FUTURE = 10  # DO NOT CHANGE THIS\n",
        "    SHIFT = 1  # DO NOT CHANGE THIS\n",
        "\n",
        "    train_set = windowed_dataset(series=x_train, batch_size=BATCH_SIZE,\n",
        "                                 n_past=N_PAST, n_future=N_FUTURE,\n",
        "                                 shift=SHIFT)\n",
        "    valid_set = windowed_dataset(series=x_valid, batch_size=BATCH_SIZE,\n",
        "                                 n_past=N_PAST, n_future=N_FUTURE,\n",
        "                                 shift=SHIFT)\n",
        "    # Code to define your model.\n",
        "    model = tf.keras.models.Sequential([\n",
        "        Conv1D(filters=32, kernel_size=5, padding='causal', activation='relu', input_shape=[N_PAST, 1]),\n",
        "        Bidirectional(LSTM(32, return_sequences=True)),    #lstm만 사용하면 점수가 안나옴 \n",
        "        Bidirectional(LSTM(32, return_sequences=True)),    #many to many bidirectional층이라서 \n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(16, activation='relu'),  \n",
        "        tf.keras.layers.Dense(N_FEATURES)\n",
        "    ])\n",
        "    checkpoint_path = 'model/my_checkpoint.ckpt'\n",
        "    checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                             save_weights_only=True,\n",
        "                             save_best_only=True,\n",
        "                             monitor='val_mae',\n",
        "                             verbose=1)\n",
        "    \n",
        "    # Code to train and compile the model\n",
        "    optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=tf.keras.losses.Huber(), metrics=['mae']\n",
        "    )\n",
        "    model.fit(\n",
        "        train_set,\n",
        "        validation_data=(valid_set),\n",
        "        epochs=100,\n",
        "        callbacks=[checkpoint]\n",
        "    )\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "    return model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLmLnTAHb6OA",
        "outputId": "9f9f7f93-e4f3-4a0b-c1e4-bfb70079b4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "     34/Unknown - 16s 43ms/step - loss: 0.0534 - mae: 0.2517\n",
            "Epoch 00001: val_mae improved from inf to 0.32533, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 22s 216ms/step - loss: 0.0531 - mae: 0.2528 - val_loss: 0.0549 - val_mae: 0.3253\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0375 - mae: 0.2019\n",
            "Epoch 00002: val_mae improved from 0.32533 to 0.25625, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 2s 59ms/step - loss: 0.0375 - mae: 0.2019 - val_loss: 0.0347 - val_mae: 0.2563\n",
            "Epoch 3/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0215 - mae: 0.1508\n",
            "Epoch 00003: val_mae improved from 0.25625 to 0.15567, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 2s 49ms/step - loss: 0.0211 - mae: 0.1501 - val_loss: 0.0138 - val_mae: 0.1557\n",
            "Epoch 4/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.1068\n",
            "Epoch 00004: val_mae improved from 0.15567 to 0.05648, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0084 - mae: 0.1049 - val_loss: 0.0025 - val_mae: 0.0565\n",
            "Epoch 5/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0056 - mae: 0.0920\n",
            "Epoch 00005: val_mae improved from 0.05648 to 0.04121, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 0.0055 - mae: 0.0908 - val_loss: 0.0013 - val_mae: 0.0412\n",
            "Epoch 6/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0050 - mae: 0.0861\n",
            "Epoch 00006: val_mae improved from 0.04121 to 0.03871, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0048 - mae: 0.0845 - val_loss: 0.0012 - val_mae: 0.0387\n",
            "Epoch 7/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0037 - mae: 0.0731\n",
            "Epoch 00007: val_mae improved from 0.03871 to 0.03530, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0036 - mae: 0.0724 - val_loss: 0.0010 - val_mae: 0.0353\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0027 - mae: 0.0604\n",
            "Epoch 00008: val_mae improved from 0.03530 to 0.03278, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0027 - mae: 0.0604 - val_loss: 9.3465e-04 - val_mae: 0.0328\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0021 - mae: 0.0512\n",
            "Epoch 00009: val_mae improved from 0.03278 to 0.03104, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0021 - mae: 0.0512 - val_loss: 8.6435e-04 - val_mae: 0.0310\n",
            "Epoch 10/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0018 - mae: 0.0440\n",
            "Epoch 00010: val_mae improved from 0.03104 to 0.03017, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0018 - mae: 0.0440 - val_loss: 8.2877e-04 - val_mae: 0.0302\n",
            "Epoch 11/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0016 - mae: 0.0394\n",
            "Epoch 00011: val_mae improved from 0.03017 to 0.02939, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0016 - mae: 0.0394 - val_loss: 7.9971e-04 - val_mae: 0.0294\n",
            "Epoch 12/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0014 - mae: 0.0352\n",
            "Epoch 00012: val_mae improved from 0.02939 to 0.02870, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0015 - mae: 0.0365 - val_loss: 7.7166e-04 - val_mae: 0.0287\n",
            "Epoch 13/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0345\n",
            "Epoch 00013: val_mae improved from 0.02870 to 0.02817, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0015 - mae: 0.0347 - val_loss: 7.4818e-04 - val_mae: 0.0282\n",
            "Epoch 14/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0014 - mae: 0.0338\n",
            "Epoch 00014: val_mae improved from 0.02817 to 0.02808, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0014 - mae: 0.0341 - val_loss: 7.4273e-04 - val_mae: 0.0281\n",
            "Epoch 15/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0013 - mae: 0.0319\n",
            "Epoch 00015: val_mae improved from 0.02808 to 0.02790, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0014 - mae: 0.0335 - val_loss: 7.3429e-04 - val_mae: 0.0279\n",
            "Epoch 16/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0014 - mae: 0.0330\n",
            "Epoch 00016: val_mae improved from 0.02790 to 0.02787, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0014 - mae: 0.0330 - val_loss: 7.3116e-04 - val_mae: 0.0279\n",
            "Epoch 17/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0014 - mae: 0.0324\n",
            "Epoch 00017: val_mae improved from 0.02787 to 0.02785, saving model to model/my_checkpoint.ckpt\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0014 - mae: 0.0327 - val_loss: 7.2786e-04 - val_mae: 0.0278\n",
            "Epoch 18/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0013 - mae: 0.0309\n",
            "Epoch 00018: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0014 - mae: 0.0326 - val_loss: 7.2937e-04 - val_mae: 0.0279\n",
            "Epoch 19/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0014 - mae: 0.0323\n",
            "Epoch 00019: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0014 - mae: 0.0323 - val_loss: 7.2564e-04 - val_mae: 0.0279\n",
            "Epoch 20/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0013 - mae: 0.0305\n",
            "Epoch 00020: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0014 - mae: 0.0322 - val_loss: 7.2834e-04 - val_mae: 0.0280\n",
            "Epoch 21/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0317\n",
            "Epoch 00021: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0321 - val_loss: 7.2672e-04 - val_mae: 0.0280\n",
            "Epoch 22/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0316\n",
            "Epoch 00022: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0320 - val_loss: 7.2864e-04 - val_mae: 0.0281\n",
            "Epoch 23/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0315\n",
            "Epoch 00023: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0319 - val_loss: 7.2840e-04 - val_mae: 0.0281\n",
            "Epoch 24/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0013 - mae: 0.0301\n",
            "Epoch 00024: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0319 - val_loss: 7.3096e-04 - val_mae: 0.0282\n",
            "Epoch 25/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0012 - mae: 0.0300\n",
            "Epoch 00025: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0318 - val_loss: 7.3002e-04 - val_mae: 0.0282\n",
            "Epoch 26/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0313\n",
            "Epoch 00026: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 25ms/step - loss: 0.0013 - mae: 0.0318 - val_loss: 7.3288e-04 - val_mae: 0.0283\n",
            "Epoch 27/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0317\n",
            "Epoch 00027: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0317 - val_loss: 7.3283e-04 - val_mae: 0.0283\n",
            "Epoch 28/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0317\n",
            "Epoch 00028: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0013 - mae: 0.0317 - val_loss: 7.3474e-04 - val_mae: 0.0284\n",
            "Epoch 29/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0012 - mae: 0.0298\n",
            "Epoch 00029: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 25ms/step - loss: 0.0013 - mae: 0.0316 - val_loss: 7.3423e-04 - val_mae: 0.0284\n",
            "Epoch 30/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0316\n",
            "Epoch 00030: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0316 - val_loss: 7.3661e-04 - val_mae: 0.0285\n",
            "Epoch 31/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0315\n",
            "Epoch 00031: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0013 - mae: 0.0315 - val_loss: 7.3693e-04 - val_mae: 0.0285\n",
            "Epoch 32/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0012 - mae: 0.0297\n",
            "Epoch 00032: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0013 - mae: 0.0315 - val_loss: 7.3855e-04 - val_mae: 0.0286\n",
            "Epoch 33/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0309\n",
            "Epoch 00033: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0314 - val_loss: 7.3768e-04 - val_mae: 0.0286\n",
            "Epoch 34/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0314\n",
            "Epoch 00034: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0314 - val_loss: 7.4136e-04 - val_mae: 0.0287\n",
            "Epoch 35/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0314\n",
            "Epoch 00035: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0314 - val_loss: 7.4035e-04 - val_mae: 0.0287\n",
            "Epoch 36/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0308\n",
            "Epoch 00036: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0314 - val_loss: 7.4232e-04 - val_mae: 0.0287\n",
            "Epoch 37/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0012 - mae: 0.0294\n",
            "Epoch 00037: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0313 - val_loss: 7.4157e-04 - val_mae: 0.0287\n",
            "Epoch 38/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0307\n",
            "Epoch 00038: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0313 - val_loss: 7.4452e-04 - val_mae: 0.0288\n",
            "Epoch 39/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0312\n",
            "Epoch 00039: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0312 - val_loss: 7.4237e-04 - val_mae: 0.0288\n",
            "Epoch 40/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0312\n",
            "Epoch 00040: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0312 - val_loss: 7.4838e-04 - val_mae: 0.0289\n",
            "Epoch 41/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0012 - mae: 0.0293\n",
            "Epoch 00041: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0312 - val_loss: 7.4467e-04 - val_mae: 0.0289\n",
            "Epoch 42/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0311\n",
            "Epoch 00042: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0013 - mae: 0.0311 - val_loss: 7.4674e-04 - val_mae: 0.0289\n",
            "Epoch 43/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0311\n",
            "Epoch 00043: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0013 - mae: 0.0311 - val_loss: 7.4591e-04 - val_mae: 0.0289\n",
            "Epoch 44/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0311\n",
            "Epoch 00044: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0311 - val_loss: 7.4794e-04 - val_mae: 0.0290\n",
            "Epoch 45/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0305\n",
            "Epoch 00045: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0013 - mae: 0.0311 - val_loss: 7.4547e-04 - val_mae: 0.0289\n",
            "Epoch 46/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0305\n",
            "Epoch 00046: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0311 - val_loss: 7.4916e-04 - val_mae: 0.0290\n",
            "Epoch 47/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0310\n",
            "Epoch 00047: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 0.0013 - mae: 0.0310 - val_loss: 7.4588e-04 - val_mae: 0.0290\n",
            "Epoch 48/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0310\n",
            "Epoch 00048: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0013 - mae: 0.0310 - val_loss: 7.4956e-04 - val_mae: 0.0291\n",
            "Epoch 49/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0304\n",
            "Epoch 00049: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0310 - val_loss: 7.4756e-04 - val_mae: 0.0290\n",
            "Epoch 50/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0303\n",
            "Epoch 00050: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0310 - val_loss: 7.5006e-04 - val_mae: 0.0291\n",
            "Epoch 51/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0303\n",
            "Epoch 00051: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0013 - mae: 0.0309 - val_loss: 7.4667e-04 - val_mae: 0.0290\n",
            "Epoch 52/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0303\n",
            "Epoch 00052: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0013 - mae: 0.0309 - val_loss: 7.4914e-04 - val_mae: 0.0291\n",
            "Epoch 53/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0302\n",
            "Epoch 00053: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0309 - val_loss: 7.4965e-04 - val_mae: 0.0291\n",
            "Epoch 54/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0308\n",
            "Epoch 00054: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0013 - mae: 0.0308 - val_loss: 7.5022e-04 - val_mae: 0.0291\n",
            "Epoch 55/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0012 - mae: 0.0289\n",
            "Epoch 00055: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0013 - mae: 0.0308 - val_loss: 7.4939e-04 - val_mae: 0.0291\n",
            "Epoch 56/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0308\n",
            "Epoch 00056: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0013 - mae: 0.0308 - val_loss: 7.5224e-04 - val_mae: 0.0292\n",
            "Epoch 57/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0301\n",
            "Epoch 00057: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0013 - mae: 0.0308 - val_loss: 7.5229e-04 - val_mae: 0.0292\n",
            "Epoch 58/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0012 - mae: 0.0288\n",
            "Epoch 00058: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0308 - val_loss: 7.5336e-04 - val_mae: 0.0292\n",
            "Epoch 59/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0012 - mae: 0.0288\n",
            "Epoch 00059: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0308 - val_loss: 7.5697e-04 - val_mae: 0.0293\n",
            "Epoch 60/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0011 - mae: 0.0287\n",
            "Epoch 00060: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0308 - val_loss: 7.5847e-04 - val_mae: 0.0294\n",
            "Epoch 61/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0301\n",
            "Epoch 00061: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0307 - val_loss: 7.6388e-04 - val_mae: 0.0295\n",
            "Epoch 62/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0301\n",
            "Epoch 00062: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0308 - val_loss: 7.6398e-04 - val_mae: 0.0296\n",
            "Epoch 63/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0307\n",
            "Epoch 00063: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0307 - val_loss: 7.6631e-04 - val_mae: 0.0297\n",
            "Epoch 64/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0300\n",
            "Epoch 00064: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0307 - val_loss: 7.7463e-04 - val_mae: 0.0299\n",
            "Epoch 65/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0308\n",
            "Epoch 00065: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0308 - val_loss: 7.7809e-04 - val_mae: 0.0300\n",
            "Epoch 66/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0300\n",
            "Epoch 00066: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0307 - val_loss: 7.8206e-04 - val_mae: 0.0301\n",
            "Epoch 67/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0011 - mae: 0.0286\n",
            "Epoch 00067: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0307 - val_loss: 7.8926e-04 - val_mae: 0.0303\n",
            "Epoch 68/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0011 - mae: 0.0285\n",
            "Epoch 00068: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0307 - val_loss: 7.9400e-04 - val_mae: 0.0305\n",
            "Epoch 69/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0300\n",
            "Epoch 00069: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0307 - val_loss: 8.0224e-04 - val_mae: 0.0307\n",
            "Epoch 70/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0011 - mae: 0.0285\n",
            "Epoch 00070: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0307 - val_loss: 8.0754e-04 - val_mae: 0.0309\n",
            "Epoch 71/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0307\n",
            "Epoch 00071: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0307 - val_loss: 8.1589e-04 - val_mae: 0.0311\n",
            "Epoch 72/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0306\n",
            "Epoch 00072: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0306 - val_loss: 8.0533e-04 - val_mae: 0.0308\n",
            "Epoch 73/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0011 - mae: 0.0283\n",
            "Epoch 00073: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0305 - val_loss: 8.1959e-04 - val_mae: 0.0312\n",
            "Epoch 74/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0011 - mae: 0.0283\n",
            "Epoch 00074: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0305 - val_loss: 8.0133e-04 - val_mae: 0.0308\n",
            "Epoch 75/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0304\n",
            "Epoch 00075: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0304 - val_loss: 8.1743e-04 - val_mae: 0.0311\n",
            "Epoch 76/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0011 - mae: 0.0282\n",
            "Epoch 00076: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0304 - val_loss: 8.1479e-04 - val_mae: 0.0311\n",
            "Epoch 77/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0305\n",
            "Epoch 00077: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0305 - val_loss: 8.2506e-04 - val_mae: 0.0313\n",
            "Epoch 78/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0304\n",
            "Epoch 00078: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 0.0012 - mae: 0.0304 - val_loss: 8.1700e-04 - val_mae: 0.0312\n",
            "Epoch 79/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0304\n",
            "Epoch 00079: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 0.0012 - mae: 0.0304 - val_loss: 8.2737e-04 - val_mae: 0.0314\n",
            "Epoch 80/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0303\n",
            "Epoch 00080: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0303 - val_loss: 8.2384e-04 - val_mae: 0.0314\n",
            "Epoch 81/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0011 - mae: 0.0280\n",
            "Epoch 00081: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0303 - val_loss: 8.2693e-04 - val_mae: 0.0314\n",
            "Epoch 82/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0011 - mae: 0.0279\n",
            "Epoch 00082: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 0.0012 - mae: 0.0302 - val_loss: 8.2732e-04 - val_mae: 0.0315\n",
            "Epoch 83/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0302\n",
            "Epoch 00083: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0302 - val_loss: 8.2627e-04 - val_mae: 0.0314\n",
            "Epoch 84/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0301\n",
            "Epoch 00084: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0301 - val_loss: 8.2246e-04 - val_mae: 0.0314\n",
            "Epoch 85/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0301\n",
            "Epoch 00085: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 2s 52ms/step - loss: 0.0012 - mae: 0.0301 - val_loss: 8.2505e-04 - val_mae: 0.0314\n",
            "Epoch 86/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0301\n",
            "Epoch 00086: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 2s 55ms/step - loss: 0.0012 - mae: 0.0301 - val_loss: 8.2397e-04 - val_mae: 0.0314\n",
            "Epoch 87/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0300\n",
            "Epoch 00087: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 2s 54ms/step - loss: 0.0012 - mae: 0.0300 - val_loss: 8.2483e-04 - val_mae: 0.0314\n",
            "Epoch 88/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0292\n",
            "Epoch 00088: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0300 - val_loss: 8.2588e-04 - val_mae: 0.0315\n",
            "Epoch 89/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0300\n",
            "Epoch 00089: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0300 - val_loss: 8.2695e-04 - val_mae: 0.0315\n",
            "Epoch 90/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0300\n",
            "Epoch 00090: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0300 - val_loss: 8.2877e-04 - val_mae: 0.0316\n",
            "Epoch 91/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0299\n",
            "Epoch 00091: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0299 - val_loss: 8.2943e-04 - val_mae: 0.0316\n",
            "Epoch 92/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0010 - mae: 0.0276\n",
            "Epoch 00092: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0299 - val_loss: 8.3225e-04 - val_mae: 0.0317\n",
            "Epoch 93/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0290\n",
            "Epoch 00093: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0299 - val_loss: 8.3327e-04 - val_mae: 0.0317\n",
            "Epoch 94/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0010 - mae: 0.0275\n",
            "Epoch 00094: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0298 - val_loss: 8.3646e-04 - val_mae: 0.0318\n",
            "Epoch 95/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0290\n",
            "Epoch 00095: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 0.0011 - mae: 0.0298 - val_loss: 8.3904e-04 - val_mae: 0.0319\n",
            "Epoch 96/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0010 - mae: 0.0274\n",
            "Epoch 00096: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0011 - mae: 0.0298 - val_loss: 8.4256e-04 - val_mae: 0.0320\n",
            "Epoch 97/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0010 - mae: 0.0274\n",
            "Epoch 00097: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 0.0011 - mae: 0.0298 - val_loss: 8.4515e-04 - val_mae: 0.0321\n",
            "Epoch 98/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0297\n",
            "Epoch 00098: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 0.0011 - mae: 0.0297 - val_loss: 8.4874e-04 - val_mae: 0.0322\n",
            "Epoch 99/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0288\n",
            "Epoch 00099: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 0.0011 - mae: 0.0297 - val_loss: 8.5208e-04 - val_mae: 0.0322\n",
            "Epoch 100/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0297\n",
            "Epoch 00100: val_mae did not improve from 0.02785\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 0.0011 - mae: 0.0297 - val_loss: 8.5553e-04 - val_mae: 0.0323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graphdf = pd.read_csv('Weekly_U.S.Diesel_Retail_Prices.csv?dl=1',\n",
        "                     infer_datetime_format=True, index_col='Week of', header=0)\n",
        "graphdf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "nW_6MIg9cD3w",
        "outputId": "89931fa0-8cca-4aef-ae65-f58c8db8ac4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5bd27d83-ef6c-4bbf-a4f8-484235a6cf4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weekly U.S. No 2 Diesel Retail Prices Dollars per Gallon</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Week of</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1994-03-21</th>\n",
              "      <td>1.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994-03-28</th>\n",
              "      <td>1.107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994-04-04</th>\n",
              "      <td>1.109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994-04-11</th>\n",
              "      <td>1.108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994-04-18</th>\n",
              "      <td>1.105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bd27d83-ef6c-4bbf-a4f8-484235a6cf4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5bd27d83-ef6c-4bbf-a4f8-484235a6cf4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5bd27d83-ef6c-4bbf-a4f8-484235a6cf4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Weekly U.S. No 2 Diesel Retail Prices Dollars per Gallon\n",
              "Week of                                                             \n",
              "1994-03-21                                              1.106       \n",
              "1994-03-28                                              1.107       \n",
              "1994-04-04                                              1.109       \n",
              "1994-04-11                                              1.108       \n",
              "1994-04-18                                              1.105       "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(graphdf.index, graphdf['Weekly U.S. No 2 Diesel Retail Prices Dollars per Gallon'])\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Result')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "fVD0pvcOcEVG",
        "outputId": "20a6a0ef-b691-4349-84b7-c4894b0914b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}